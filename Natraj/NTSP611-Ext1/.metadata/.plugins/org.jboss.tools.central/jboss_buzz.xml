<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>AI/ML pipelines using Open Data Hub and Kubeflow on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/wukRXx_2ge4/" /><category term="Containers" /><category term="Machine Learning" /><category term="Red Hat OpenShift Container Platform" /><category term="Kubeflow" /><category term="Open Data Hub" /><author><name>Juana Nakfour</name></author><id>https://developers.redhat.com/blog/?p=659347</id><updated>2019-12-16T08:00:08Z</updated><published>2019-12-16T08:00:08Z</published><content type="html">&lt;p&gt;When it comes to the process of optimizing a production-level artificial intelligence/machine learning (AI/ML) process, workflows and pipelines are an integral part of this effort. Pipelines are used to create workflows that are repeatable, automated, customizable, and intelligent.&lt;/p&gt; &lt;p&gt;An example AI/ML pipeline is presented in Figure 1, where functionalities such as data extract, transform, and load (ETL), model training, model evaluation, and model serving are automated as part of the pipeline.&lt;span id="more-659347"&gt;&lt;/span&gt;&lt;/p&gt; &lt;div id="attachment_659357" style="width: 552px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-659357" class="wp-image-659357 " src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-2.46.17-PM-300x254.png" alt="" width="542" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-2.46.17-PM-300x254.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-2.46.17-PM.png 554w" sizes="(max-width: 542px) 100vw, 542px" /&gt;&lt;p id="caption-attachment-659357" class="wp-caption-text"&gt;Figure 1: AI/ML example pipeline.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The attributes and features of an AI/ML pipeline are many, including the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Automation&lt;/strong&gt;: The ability to automate the workflow steps without any manual intervention.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Repeatability&lt;/strong&gt;: The ability to repeat steps such as re-training a model or re-evaluating a model with only input parameter changes.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Artifact passing (input, output)&lt;/strong&gt;: The ability to pass data between workflow steps, sometimes if conditions and loops are dependent on this data.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Triggers&lt;/strong&gt;: The ability to automate triggering a workflow, without manually starting the pipeline. Triggers such as calendar events, messaging and monitoring events are used in many use cases.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multi-cluster&lt;/strong&gt;: The ability to run a pipeline spanning multiple clusters such as the case in Hybrid Clouds. In many use cases, data resides in a different cluster than where processing takes place.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Step or DAG (Directed Acyclic Graph) features&lt;/strong&gt;: Most comprehensive pipelines require a DAG structure with features such as targets, parallel processing, conditionals, loops, pause/resume, timeouts, and retries.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are many AI/ML pipeline tools today, and the most popular native Kubernetes tools are &lt;a href="https://argoproj.github.io/argo/"&gt;Argo&lt;/a&gt; and &lt;a href="https://www.kubeflow.org/"&gt;Kubeflow&lt;/a&gt; pipelines. In the next sections, we will describe using Open Data Hub and Kubeflow pipelines, both of which use Argo as the AI/ML pipeline tool.&lt;/p&gt; &lt;h2&gt;Open Data Hub&lt;/h2&gt; &lt;p&gt;&lt;a href="https://opendatahub.io/news/2018-12-04/open-data-hub-overview.html"&gt;Open Data Hub (ODH)&lt;/a&gt; is an open source end to end AI/ML platform that runs native to &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;. Open Data Hub is a meta operator that includes many tools needed for end-to-end AI/ML development and production workflows and can be installed from Openshift 4.x Catalog Community Operators. For pipeline development, ODH includes an installation of the Argo workflow tool.&lt;/p&gt; &lt;p&gt;&lt;a href="https://opendatahub.io/docs/getting-started/quick-installation.html"&gt;Argo workflow&lt;/a&gt; is an open source &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; container-native workflow engine for orchestrating pipelines on Kubernetes. Pipeline steps are defined as native Kubernetes containers using YAML. A multi-step pipeline can be defined as a DAG with features such as input/outputs for each step, loops, parameterization, conditionals, timeouts (step &amp;#38; workflow level), and retry (step &amp;#38; workflow level). Argo defines a Kubernetes custom resource called workflow to create pipelines.&lt;/p&gt; &lt;p&gt;Integrating Argo into the ODH operator required writing an Ansible role that installs the required manifest for Argo. It also includes specific role-based access control (RBAC) for namespace bound installation and specifically uses “k8sapi” as executor as opposed to docker, as the default registry in Openshift is CRI-O. (CRI-O replaced the previously provided Docker engine in Openshift 4.x.) In the next section, we define the steps to install ODH and run an example Argo workflow.&lt;/p&gt; &lt;h3&gt;Installing and Running ODH Argo&lt;/h3&gt; &lt;p&gt;The basic requirement to install ODH is Red Hat Openshift 3.11 or 4.x. For step-by-step instructions, please follow the &lt;a href="https://opendatahub.io/docs/getting-started/quick-installation.html"&gt;Open Data Hub Quick Installation Guide&lt;/a&gt;. However, in Step 4 for creating an instance of ODH, make sure to set “true” for Argo components are shown in Figure 2 below.&lt;/p&gt; &lt;div id="attachment_659377" style="width: 307px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-659377" class="wp-image-659377 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-3.30.10-PM.png" alt="" width="297" height="209" /&gt;&lt;p id="caption-attachment-659377" class="wp-caption-text"&gt;Figure 2: Specify &amp;#8220;true&amp;#8221; for Argo component in the CR(Custom Resource) file.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After installation is complete, verify that Argo installed by checking the two pods created for Argo: argo-ui and workflow-controller. To launch the Argo UI portal, click on the Argo UI route in the networking section. For a simple test, we can run the &amp;#8220;hello world&amp;#8221; example provided by the Argo project. Create a hello-world.yaml file with the code below.&lt;/p&gt; &lt;pre&gt;apiVersion: argoproj.io/v1alpha1 kind: &lt;b&gt;Workflow&lt;/b&gt; metadata:   generateName: hello-world- &lt;b&gt;spec:&lt;/b&gt;   entrypoint: whalesay   templates:   - name: whalesay &lt;b&gt;     container:&lt;/b&gt;         image: docker/whalesay:latest         command: [cowsay]         args: ["hello world"]&lt;/pre&gt; &lt;p&gt;From a terminal, make sure you are in the ODH namespace and run:&lt;/p&gt; &lt;pre&gt;oc create -f hello-world.yaml&lt;/pre&gt; &lt;p&gt;Check the Argo portal to see the workflow progress and see the &amp;#8220;hello world&amp;#8221; log message. For a more comprehensive example, we provide an example DAG pipeline that includes a for loop, a conditional loop, parallel processing, and artifact access for remote S3 buckets. The workflow is shown in Figure 3, and the YAML file is also provided.&lt;/p&gt; &lt;div id="attachment_659387" style="width: 724px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-659387" class="wp-image-659387 " src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-3.37.48-PM-300x148.png" alt="" width="714" height="352" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-3.37.48-PM-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-3.37.48-PM-768x379.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-26-at-3.37.48-PM.png 958w" sizes="(max-width: 714px) 100vw, 714px" /&gt;&lt;p id="caption-attachment-659387" class="wp-caption-text"&gt;Figure 3: Example pipeline with for loop, a conditional loop, parallel processing, and artifact access for remote S3 buckets.&lt;/p&gt;&lt;/div&gt; &lt;pre&gt;apiVersion: argoproj.io/v1alpha1 kind: &lt;strong&gt;Workflow&lt;/strong&gt; metadata:   generateName: frauddetection &lt;strong&gt;spec&lt;/strong&gt;:   entrypoint: fraud-workflow   serviceAccountName: argo-workflow   &lt;strong&gt;volumes&lt;/strong&gt;:   - name: workdir&amp;#62;     emptyDir: {}   &lt;strong&gt;templates&lt;/strong&gt;:   - name: echo     inputs:       parameters:       - name: message     &lt;strong&gt;container&lt;/strong&gt;:       env:       - name: ACCESS_KEY_ID         valueFrom:           secretKeyRef:             name: keysecret             key: accesskey       - name: SECRET_ACCESS_KEY         valueFrom:           secretKeyRef:             name: keysecret             key: secretkey       - name: S3_ENDPOINT_URL         value: "insert s3 url"       image: alpine:3.7       command: [echo, "{{inputs.parameters.message}}"]   - name: whalesay     &lt;strong&gt;container&lt;/strong&gt;:       image: docker/whalesay:latest       command: [sh, -c]       args: ["sleep 1; echo -n true &amp;#62; /tmp/hyper.txt"]   - name: volumes-emptydir-example     &lt;strong&gt;container&lt;/strong&gt;:       image: debian:latest       command: ["/bin/bash", "-c"]       args: ["         vol_found=`mount | grep /mnt/vol` &amp;#38;&amp;#38; \         if [[ -n $vol_found ]]; then echo \"Volume mounted and found\"; else echo \"Not found\"; fi; sleep 1; echo -n true &amp;#62; /mnt/vol/hyper.txt"]&amp;#62;       volumeMounts:       - name: workdir         mountPath: /mnt/vol     outputs:       parameters:       - name: should-hyper         valueFrom:           path: /mnt/vol/hyper.txt   - name: fraud-workflow     &lt;strong&gt;dag&lt;/strong&gt;:       &lt;strong&gt;tasks&lt;/strong&gt;:       - name: Read-Data-AWS         template: echo         arguments:           parameters: [{name: message, value: Read-Data-AWS}]       - name: Read-Data-Ceph         dependencies:         template: echo         arguments:           parameters: [{name: message, value: Read-Data-Ceph}]       - name: Transform-Data         dependencies: [Read-Data-Ceph,Read-Data-AWS]         template: volumes-emptydir-example       - name: Hyper-Tuning         dependencies: [Transform-Data]         template: echo         when: "{{tasks.Transform-Data.outputs.parameters.should-hyper}} == true"         arguments:           parameters: [{name: message, value: Hyper-Tuning}]       - name: Train-Model         dependencies: [Transform-Data,Hyper-Tuning]         template: echo         arguments:           parameters: [{name: message, value: Train-Model}]       - name: Validate-Model         dependencies: [Train-Model]         template: echo         arguments:           parameters: [{name: message, value: "{{item}}"}]         withItems:         - hello world         - goodbye world       - name: Publish-Model         dependencies: [Validate-Model]         template: echo         arguments:           parameters: [{name: message, value: Publish-Model}]&lt;/pre&gt; &lt;p&gt;From the workflow description, we can see that S3 settings are passed to template &amp;#8220;echo&amp;#8221; from an OpenShift secret. The if condition is implemented for the “Hyper-Tuning” step on condition that parameter “should-hyper” is true. This parameter is specified by the “Transform Data” step. The for loop example is shown in the “Validate model” step that runs twice, once with “hello world” and once with “goodbye world” as parameters to the container.&lt;/p&gt; &lt;h3&gt;Using Kubeflow Pipelines&lt;/h3&gt; &lt;p&gt;Kubeflow is an open source AI/ML project focused on model training, serving, pipelines, and metadata. The Kubeflow pipeline tool uses Argo as the underlying tool for executing the pipelines. However, Kubeflow provides a layer above Argo to allow data scientists to write pipelines using Python as opposed to YAML files. The project provides a Python SDK to be used when building the pipelines. Kubeflow also provides a pipeline portal that allows for running experiments with metrics and metadata for specific pipelines. This allows users to track and repeat experiments with specific metrics. For detailed information on Kubeflow project, please visit &lt;a href="http://kubeflow.org"&gt;kubeflow.org&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As part of the Open Data Hub project, we have adapted and installed Kubeflow on OCP 4.x. Our work can be followed on the &lt;a href="https://github.com/opendatahub-io/kubeflow"&gt;GitHub Open Data Hub&lt;/a&gt; project.&lt;/p&gt; &lt;p&gt;To run the &amp;#8220;hello world&amp;#8221; example workflow, there are two options: You can either run an experiment from the Kubeflow pipeline portal and upload the YAML file, or write the Python version of the workflow and compile it using the SDK then upload to the portal in an experiment.&lt;/p&gt; &lt;p&gt;For a comparison between a  &amp;#8220;hello world&amp;#8221; example using YAML and Python, see Figure 4 below. As shown, every Python pipeline is translated to a YAML pipeline with metadata.&lt;/p&gt; &lt;div id="attachment_659517" style="width: 709px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-659517" class="wp-image-659517 " src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.24.16-AM-300x148.png" alt="" width="699" height="345" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.24.16-AM-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.24.16-AM-768x380.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.24.16-AM-1024x507.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.24.16-AM.png 1051w" sizes="(max-width: 699px) 100vw, 699px" /&gt;&lt;p id="caption-attachment-659517" class="wp-caption-text"&gt;Figure 4: A comparison of the &amp;#8220;hello world&amp;#8221; pipeline between YAML and Python format.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;For a comparison between running YAML Argo workflows versus Kubeflow Python workflows, see Figure 5 with step-by-step instructions. As you can see, using Python requires compiling the code and storing it in a compressed tar.gz file that can then be uploaded to the Kubeflow portal.&lt;/p&gt; &lt;div id="attachment_659537" style="width: 822px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-659537" class="wp-image-659537 " src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.27.04-AM-300x119.png" alt="" width="812" height="322" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.27.04-AM-300x119.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.27.04-AM-768x305.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-27-at-11.27.04-AM.png 985w" sizes="(max-width: 812px) 100vw, 812px" /&gt;&lt;p id="caption-attachment-659537" class="wp-caption-text"&gt;Figure 5: Comparing Argo and Kubeflow pipeline creation.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Future considerations&lt;/h2&gt; &lt;p&gt;Many of the available AI/ML pipeline tools are missing some important features, such as triggers. The Argo project does include the Argo events tool that provides triggers to run workflows, but it is still in early stages. OpenShift cron jobs can be used to trigger workflows, but they do have limitations, such as triggering a workflow based on a messaging stream. Monitoring is also critical in managing a cluster and is provided by Argo as a metrics scraping interface for Prometheus; however, monitoring success or failure in a workflow is lacking. Multi-cluster pipelines are not currently available, but there is a tool from Argo in its early stages that allows running workflow steps in different clusters.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#38;linkname=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#38;linkname=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#38;linkname=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#38;linkname=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#38;linkname=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#38;linkname=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#38;linkname=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F16%2Fai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift%2F&amp;#038;title=AI%2FML%20pipelines%20using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2019/12/16/ai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift/" data-a2a-title="AI/ML pipelines using Open Data Hub and Kubeflow on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/16/ai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift/"&gt;AI/ML pipelines using Open Data Hub and Kubeflow on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/wukRXx_2ge4" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;When it comes to the process of optimizing a production-level artificial intelligence/machine learning (AI/ML) process, workflows and pipelines are an integral part of this effort. Pipelines are used to create workflows that are repeatable, automated, customizable, and intelligent. An example AI/ML pipeline is presented in Figure 1, where functionalities such as data extract, transform, and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/16/ai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift/"&gt;AI/ML pipelines using Open Data Hub and Kubeflow on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">659347</post-id><dc:creator>Juana Nakfour</dc:creator><dc:date>2019-12-16T08:00:08Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/16/ai-ml-pipelines-using-open-data-hub-and-kubeflow-on-red-hat-openshift/</feedburner:origLink></entry><entry><title>Jakarta EE: Creating an Enterprise JavaBeans timer</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rjom_Czg8Ho/" /><category term="Java" /><category term="Enterprise JavaBeans" /><author><name>rhsilva</name></author><id>https://developers.redhat.com/blog/?p=652897</id><updated>2019-12-13T08:00:49Z</updated><published>2019-12-13T08:00:49Z</published><content type="html">&lt;p&gt;&lt;a href="https://www.javaworld.com/article/2076777/a-beginner-s-guide-to-enterprise-javabeans.html"&gt;Enterprise JavaBeans&lt;/a&gt; (EJB) has many interesting and useful features, some of which I will be highlighting in this and upcoming articles. In this article, I&amp;#8217;ll show you how to create an&lt;a href="https://docs.oracle.com/cd/E16439_01/doc.1013/e13981/undejdev012.htm"&gt; EJB timer&lt;/a&gt; programmatically and with annotation. Let&amp;#8217;s go!&lt;/p&gt; &lt;p&gt;The EJB timer feature allows us to schedule tasks to be executed according a calendar configuration. It is very useful because we can execute scheduled tasks using the power of &lt;a href="https://developers.redhat.com/blog/2019/09/12/jakarta-ee-8-the-new-era-of-java-ee-explained/"&gt;Jakarta&lt;/a&gt; context. When we run tasks based on a timer, we need to answer some questions about concurrency, which node the task was scheduled on (in case of an application in a cluster), what is the action if the task does not execute, and others. When we use the EJB timer we can delegate many of these concerns to Jakarta context and care more about business logic. It is interesting, isn&amp;#8217;t it?&lt;span id="more-652897"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Creating an EJB timer programmatically&lt;/h2&gt; &lt;p&gt;We can schedule an EJB timer to runs according to a business logic using a programmatic approach. This method can be used when we want a dynamic behavior, according to the parameter values passed to the process. Let&amp;#8217;s look at an example of an EJB timer:&lt;/p&gt; &lt;pre&gt;import javax.annotation.Resource; import javax.ejb.SessionContext; import javax.ejb.Stateless; import javax.ejb.Timeout; import java.util.logging.Logger; @Stateless public class MyTimer { private Logger logger = Logger.getLogger(MyTimer.class.getName()); @Resource private SessionContext context; public void initTimer(String message){ context.getTimerService().createTimer(10000, message); } @Timeout public void execute(){ logger.info("Starting"); context.getTimerService().getAllTimers().stream().forEach(timer -&amp;#62; logger.info(String.valueOf(timer.getInfo()))); logger.info("Ending"); } } &lt;/pre&gt; &lt;p&gt;To schedule this EJB timer, call this method:&lt;/p&gt; &lt;pre&gt;@Inject private MyTimer myTimer; ....&lt;/pre&gt; &lt;pre&gt;myTimer.initTimer(message);&lt;/pre&gt; &lt;p&gt;After passing 10000 milliseconds, the method annotated with @Timeout will be called.&lt;/p&gt; &lt;h2&gt;Scheduling an EJB timer using annotation&lt;/h2&gt; &lt;p&gt;We can also create an EJB timer that is automatically scheduled to run according to an annotation configuration. Look at this example:&lt;/p&gt; &lt;pre&gt;@Singleton public class MyTimerAutomatic { private Logger logger = Logger.getLogger(MyTimerAutomatic.class.getName()); @Schedule(hour = "*", minute = "*",second = "0,10,20,30,40,50",persistent = false) public void execute(){ logger.info("Automatic timer executing"); } } &lt;/pre&gt; &lt;p&gt;As you can see, to configure an automatic EJB timer schedule, you can annotate the method using @Schedule and configure the calendar attributes. For example:&lt;/p&gt; &lt;pre&gt;@Schedule(hour = "*", minute = "*",second = "0,10,20,30,40,50",persistent = false)&lt;/pre&gt; &lt;p&gt;As you can see, the method execute is configured to be called every 10 seconds. You can configure whether the timer is persistent as well.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;EJB timer is a good EJB feature that is helpful in solving many problems. Using the EJB timer feature, we can schedule tasks to be executed, thereby delegating some responsibilities to Jakarta context to solve for us. Furthermore, we can create persistent timers, control the concurrent execution, and work with it in a clustered environment.  If you want to see the complete example, visit this &lt;a href="https://github.com/rhuan080/sampleejbtime"&gt;repository&lt;/a&gt; on GitHub.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#38;linkname=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#38;linkname=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#38;linkname=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#38;linkname=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#38;linkname=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#38;linkname=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#38;linkname=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fjakarta-ee-creating-an-enterprise-javabeans-timer%2F&amp;#038;title=Jakarta%20EE%3A%20Creating%20an%20Enterprise%20JavaBeans%20timer" data-a2a-url="https://developers.redhat.com/blog/2019/12/13/jakarta-ee-creating-an-enterprise-javabeans-timer/" data-a2a-title="Jakarta EE: Creating an Enterprise JavaBeans timer"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/13/jakarta-ee-creating-an-enterprise-javabeans-timer/"&gt;Jakarta EE: Creating an Enterprise JavaBeans timer&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rjom_Czg8Ho" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Enterprise JavaBeans (EJB) has many interesting and useful features, some of which I will be highlighting in this and upcoming articles. In this article, I&amp;#8217;ll show you how to create an EJB timer programmatically and with annotation. Let&amp;#8217;s go! The EJB timer feature allows us to schedule tasks to be executed according a calendar configuration. It [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/13/jakarta-ee-creating-an-enterprise-javabeans-timer/"&gt;Jakarta EE: Creating an Enterprise JavaBeans timer&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">652897</post-id><dc:creator>rhsilva</dc:creator><dc:date>2019-12-13T08:00:49Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/13/jakarta-ee-creating-an-enterprise-javabeans-timer/</feedburner:origLink></entry><entry><title>We’re headed for edge computing</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/6yJe5tZCQ0E/" /><category term="Cloud" /><category term="Internet of Things" /><category term="edge deployment" /><category term="edge development" /><author><name>Ishu Verma</name></author><id>https://developers.redhat.com/blog/?p=659977</id><updated>2019-12-13T08:00:35Z</updated><published>2019-12-13T08:00:35Z</published><content type="html">&lt;p&gt;Every week seems to bring a new report on how &lt;a href="https://www.redhat.com/en/topics/edge-computing/what-is-edge-computing"&gt;edge computin&lt;/a&gt;g is going to take over the world. This crescendo has been building for the past few years, so it’s no surprise that edge computing sits near the peak on the &lt;a href="https://www.gartner.com/en/documents/3956137/hype-cycle-for-edge-computing-2019"&gt;Gartner hype cycle&lt;/a&gt; for emerging technologies. But the question remains—will the edge computing phenomenon take over the world as predicted and, if so, how can businesses benefit from it?&lt;/p&gt; &lt;p&gt;In this and future articles, we’ll demystify edge computing, examine its motivations, and explore best practices in creating scalable edge deployments and the role of open source at the edge. We&amp;#8217;ll also look at 5G and its impact to the telco industry, remote office/branch office, IoT, and other use cases.&lt;/p&gt; &lt;h2&gt;What is edge computing?&lt;/h2&gt; &lt;p&gt;Depending on the industry or use case, the term edge computing (EC) has been used to describe everything from actions performed by tiny IoT devices to datacenter-like infrastructure. Terms used to denote edge computing include: distributed computing, hybrid edge computing, heterogeneous computing, matrix computing, datacenter-in-a-box, local cloud, network edge, fog computing, and more. Depending on the industry, the meaning of each of these terms is imbued with its own perspective.&lt;/p&gt; &lt;p&gt;To add to the confusion, there is not a single edge, but a continuum of edge tiers with different properties in terms of distance to users, number of sites, size of sites, ownership, etc. The location of where edge computing is located is subject to interpretation. For service providers, EC can extend from core to the last mile, whereas for enterprises, EC is located on-premise.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;&lt;em&gt;At the conceptual level, edge computing refers to the idea of bringing computing closer to where it&amp;#8217;s consumed or closer to the sources of data. This concept is not limited to computing services but could also include networking or storage services.&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;The debate over where computing resources should be located is perhaps as old as computing itself. The pendulum often swings between efficiencies and economies of scale offered by centralized computing to flexibility and user control offered by non-centralized computing. Past trends have included client/server, PC vs. mainframe, etc.&lt;/p&gt; &lt;p&gt;The edge computing concept is more than two decades old, pioneered by Akamai for &lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network"&gt;Content Delivery Networks&lt;/a&gt; (CDNs) whereby frequently accessed content is cached closer to end users. In the present context, the edge computing scope is much broader, encompassing businesses, consumers, and service providers.&lt;/p&gt; &lt;p&gt;There is great variability across various EC use cases and industries, where every use case presents its own unique requirements for edge. For an IoT use case, how the edge operates is different from a remote site like a windmill or autonomous vehicle and also different from the requirements of a factory or stadium. For example, a remote site that has constraints on computing infrastructure and network bandwidth mostly operates in offline mode, whereas a stadium would have a mini datacenter-like infrastructure with broadband connectivity.&lt;/p&gt; &lt;h2&gt;Why is computing moving to the edge?&lt;/h2&gt; &lt;p&gt;In the past decade, the shift to cloud services has resulted in computing resources being concentrated in a few large datacenters. Edge computing is a counter-trend that decentralizes cloud services and distributes them to many sites that are located closer to end users or data sources. It allows applications to deliver a better quality experience, thereby also enabling new use cases and gaining operational efficiencies. The main reasons for EC can be categorized into areas of bandwidth, latency, resiliency, and security.&lt;/p&gt; &lt;p&gt;Some emerging use cases, like IoT or video surveillance, are expected to generate huge amounts of data (100s of GB/day) and have constrained network connectivity via cellular/satellite (e.g., offshore oil platform, ship at sea). By processing data closer to the data source, EC can help reduce network bandwidth required to move device data to back-end systems. The majority of device data could be redundant information. Think of room temperature data from a thermostat, for example, that could be processed locally with only a small aggregated dataset being sent to back-end systems.&lt;/p&gt; &lt;p&gt;For use cases like mobile AR/VR with edge-based rendering or autonomous driving with real-time decision making, the latency introduced by communicating with a centralized site over a long distance, could impact user experience or safety. EC helps reduce latencies and becomes a key requirement for time-sensitive use cases.&lt;/p&gt; &lt;p&gt;For critical business functions, edge computing provides resiliency for service continuity despite intermittent network connectivity (e.g., autonomous vehicles, smart buildings, agriculture). By limiting the affected areas of service failures to a smaller service area (e.g., mobile edge computing), it provides for greater resiliency. EC also allows for better data sovereignty by keeping sensitive information close to its source for security or regulatory reasons.&lt;/p&gt; &lt;p&gt;It’s not an either/or choice between edge computing and centralized computing. As EC gains greater adoption in the marketplace, the overall solution would encompass a combination of the two. In such a hybrid computing model, centralized computing would be used for compute-intensive workloads, data aggregation and storage, AI/machine learning, coordinating operations across geographies, and traditional back-end processing. Edge computing, on the other hand, could help solve problems at the source, in near real time.&lt;/p&gt; &lt;p&gt;Architects will need to identify use cases that are aligned with edge computing. If a use case doesn’t benefit from reduced latency, real-time monitoring, or other attributes, the customer may not find edge computing appealing.&lt;/p&gt; &lt;h2&gt;Who is using edge computing?&lt;/h2&gt; &lt;p&gt;Emerging use cases like IoT, AI/ML, AR/VR, robotics, and telco network functions are often cited as key drivers to move computing to the edge. However, traditional enterprises are also starting to adopt this approach in order to better support their remote/branch offices, retail locations, manufacturing plants, etc. Even cloud service providers have recognized the need for processing data closer to source and are offering edge solutions.&lt;/p&gt; &lt;p&gt;Analysts are forecasting a data gravity shift from core datacenters out to the edge. By 2021, consumer-facing industries will annually spend more on the network, computing, and storage resources in edge locations than on upgrades in core datacenters.&lt;/p&gt; &lt;p&gt;According to &lt;a href="https://www.idc.com/research/viewtoc.jsp?containerId=US43152417"&gt;one report by IDC&lt;/a&gt;, by 2022, local cloud offerings will account for a quarter of all hosted private cloud spending. Companies like eBay are decentralizing their cluster of data centers to create a faster, more consistent user experience, &lt;a href="https://www.datacenterknowledge.com/ebay/ebay-designs-own-servers-decentralizes-data-center-strategy"&gt;saving 600-800 milliseconds of load time&lt;/a&gt; by deploying online services and data closer to their users, enabling dynamic and static caching capabilities.&lt;/p&gt; &lt;p&gt;For companies looking for low-latency or disconnected computing, where remote sites can operate without communication with centralized infrastructure, EC can help improve the infrastructure resiliency and application availability. Edge computing can similarly benefit a large number of use cases including utilities, transportation, healthcare, industrial, energy, and retail.&lt;/p&gt; &lt;p&gt;For service providers, EC can help improve the quality of experience of their customers by moving applications or content towards the edge tiers in the network hierarchy. They can also deploy an entirely new class of services in the edge to take advantage of their proximity to the customers. As network edge represents a majority of the operator’s capital and operational expenses, it is also a key area of interest for network modernization efforts.&lt;/p&gt; &lt;p&gt;To learn more about what Red Hat is up to on edge computing, &lt;a href="https://www.redhat.com/en/topics/edge-computing"&gt;click here.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#38;linkname=We%E2%80%99re%20headed%20for%20edge%20computing" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#38;linkname=We%E2%80%99re%20headed%20for%20edge%20computing" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#38;linkname=We%E2%80%99re%20headed%20for%20edge%20computing" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#38;linkname=We%E2%80%99re%20headed%20for%20edge%20computing" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#38;linkname=We%E2%80%99re%20headed%20for%20edge%20computing" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#38;linkname=We%E2%80%99re%20headed%20for%20edge%20computing" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#38;linkname=We%E2%80%99re%20headed%20for%20edge%20computing" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F13%2Fwere-headed-for-edge-computing%2F&amp;#038;title=We%E2%80%99re%20headed%20for%20edge%20computing" data-a2a-url="https://developers.redhat.com/blog/2019/12/13/were-headed-for-edge-computing/" data-a2a-title="We’re headed for edge computing"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/13/were-headed-for-edge-computing/"&gt;We&amp;#8217;re headed for edge computing&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/6yJe5tZCQ0E" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Every week seems to bring a new report on how edge computing is going to take over the world. This crescendo has been building for the past few years, so it’s no surprise that edge computing sits near the peak on the Gartner hype cycle for emerging technologies. But the question remains—will the edge computing [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/13/were-headed-for-edge-computing/"&gt;We&amp;#8217;re headed for edge computing&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">659977</post-id><dc:creator>Ishu Verma</dc:creator><dc:date>2019-12-13T08:00:35Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/13/were-headed-for-edge-computing/</feedburner:origLink></entry><entry><title>Blueprint for omnichannel integration architecture (webinar slides)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/DUHUw-8_foE/blueprint-for-omnichannel-integration-architecture-slides.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="event" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="video" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-blueprint_for_omnichannel_integration_architecture_webinar_slides</id><updated>2019-12-12T17:00:15Z</updated><published>2019-12-12T17:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-2MhOPmyu9_g/Xck4Ts9W9NI/AAAAAAAAwuQ/x0SHf8VD42YxIDBhL80U5tAa25US2rBRgCNcBGAsYHQ/s1600/Screenshot%2B2019-11-11%2Bat%2B10.30.25.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="omnichannel integration architecture" border="0" data-original-height="434" data-original-width="1402" height="99" src="https://1.bp.blogspot.com/-2MhOPmyu9_g/Xck4Ts9W9NI/AAAAAAAAwuQ/x0SHf8VD42YxIDBhL80U5tAa25US2rBRgCNcBGAsYHQ/s320/Screenshot%2B2019-11-11%2Bat%2B10.30.25.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;Are you interested in the insights to how organizations are implementing the foundational integration building blocks that lead to successful communication with their customers?&lt;br /&gt;&lt;br /&gt;This story was presented today in a recorded available on demand webinar. &lt;a href="http://redhat.com/en/events/webinar/blueprint-omnichannel-integration-architecture" target="_blank"&gt;Register to view recording of this webinar&lt;/a&gt; and you'll gain insights on how your current architecture can map to support your customers experiences, for a detailed look at an architectural blueprint based on successful customer solutions, and receive instruction on how to discuss an omnichannel architecture in detail.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://1.bp.blogspot.com/-jTtB0UP6wE0/Xck6GCOSwKI/AAAAAAAAwuc/1Ijzd-z5p0Y35Z86tKkyO75IPvz8PdWRQCNcBGAsYHQ/s1600/Screenshot%2B2019-11-11%2Bat%2B10.37.59.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="omnichannel integration architecture" border="0" data-original-height="895" data-original-width="1600" height="179" src="https://1.bp.blogspot.com/-jTtB0UP6wE0/Xck6GCOSwKI/AAAAAAAAwuc/1Ijzd-z5p0Y35Z86tKkyO75IPvz8PdWRQCNcBGAsYHQ/s320/Screenshot%2B2019-11-11%2Bat%2B10.37.59.png" title="" width="320" /&gt;&lt;/a&gt;Here's the official abstract and slides from the webinar for your viewing pleasure:&lt;br /&gt;&lt;br /&gt;&lt;i&gt;Agile integration is a broadly scoped discussion around how to use all the services and power contained in your organization’s current architecture. While the topic is interesting in its own right, let's take a deeper look at a specific solution within the integration context: providing an omnichannel customer experience. Omnichannel is the integration and orchestration of channels to make the experience of customer engagement across all channels as efficient as engagement with 1 channel.&amp;nbsp;&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;div align="center"&gt;&lt;iframe allowfullscreen="" frameborder="0" height="420" marginheight="0" marginwidth="0" scrolling="no" src="//www.slideshare.net/slideshow/embed_code/key/y1LnGgiFYCohsx" style="border-width: 1px; border: 1px solid #ccc; margin-bottom: 5px; max-width: 100%;" width="510"&gt; &lt;/iframe&gt; &lt;/div&gt;&lt;br /&gt;&lt;a href="http://redhat.com/en/events/webinar/blueprint-omnichannel-integration-architecture" target="_blank"&gt;Be sure to register&lt;/a&gt; for access to the recorded session and feel free to reach out if you have questions&amp;nbsp; or feedback.&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=eamCt86xalo:o0HH5kub5Ck:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=eamCt86xalo:o0HH5kub5Ck:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=eamCt86xalo:o0HH5kub5Ck:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=eamCt86xalo:o0HH5kub5Ck:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=eamCt86xalo:o0HH5kub5Ck:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=eamCt86xalo:o0HH5kub5Ck:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=eamCt86xalo:o0HH5kub5Ck:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=eamCt86xalo:o0HH5kub5Ck:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=eamCt86xalo:o0HH5kub5Ck:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=eamCt86xalo:o0HH5kub5Ck:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=eamCt86xalo:o0HH5kub5Ck:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/eamCt86xalo" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/DUHUw-8_foE" height="1" width="1" alt=""/&gt;</content><summary>Are you interested in the insights to how organizations are implementing the foundational integration building blocks that lead to successful communication with their customers? This story was presented today in a recorded available on demand webinar. Register to view recording of this webinar and you'll gain insights on how your current architecture can map to support your customers experiences, ...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-12-12T17:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/eamCt86xalo/blueprint-for-omnichannel-integration-architecture-slides.html</feedburner:origLink></entry><entry><title>Future-proof monolithic applications with modular design</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1gw8dh6L0co/" /><category term="DevNation" /><category term="Events" /><category term="Eclipse Vert.x" /><category term="Quarkus" /><author><name>Editorial Team</name></author><id>https://developers.redhat.com/blog/?p=657987</id><updated>2019-12-12T08:00:53Z</updated><published>2019-12-12T08:00:53Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/devnation/"&gt;DevNation tech talks&lt;/a&gt; are hosted by the Red Hat technologists who create our products. These sessions include real solutions and code and sample projects to help you get started. In this talk, you’ll learn about future-proofing applications from Eric Murphy and Ales Nosek, Architects with Red Hat Consulting.&lt;/p&gt; &lt;p&gt;When building an MVP software application, you may immediately jump to a &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; architecture because it’s the new norm for building cloud-native applications. You may also be skeptical about starting off with a monolith because of the perception of such applications as relics of the past.&lt;/p&gt; &lt;p&gt;In this talk, we will show how to evolve a monolithic application in a highly controlled way using modular design principles. We will also demonstrate a future-proofed &lt;a href="https://developers.redhat.com/topics/quarkus/"&gt;Quarkus&lt;/a&gt; + &lt;a href="https://vertx.io/"&gt;Vert.x &lt;/a&gt;application that is both a monolith and microservices while using the same code and modular design.&lt;span id="more-657987"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Watch the entire presentation:&lt;/p&gt; &lt;p&gt;&lt;iframe src="https://www.youtube.com/embed/FC3jSKgTNK0" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h3&gt;Learn more&lt;/h3&gt; &lt;p class="selectionShareable"&gt;Join us at an upcoming&lt;a href="https://developers.redhat.com/events/"&gt; developer event&lt;/a&gt;, and see our collection of&lt;a href="https://developers.redhat.com/devnation/?page=0"&gt; past DevNation Live tech talks&lt;/a&gt;&lt;a href="https://developers.redhat.com/events/"&gt;.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#38;linkname=Future-proof%20monolithic%20applications%20with%20modular%20design" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#38;linkname=Future-proof%20monolithic%20applications%20with%20modular%20design" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#38;linkname=Future-proof%20monolithic%20applications%20with%20modular%20design" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#38;linkname=Future-proof%20monolithic%20applications%20with%20modular%20design" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#38;linkname=Future-proof%20monolithic%20applications%20with%20modular%20design" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#38;linkname=Future-proof%20monolithic%20applications%20with%20modular%20design" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#38;linkname=Future-proof%20monolithic%20applications%20with%20modular%20design" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F12%2Ffuture-proof-monolithic-applications-with-modular-design%2F&amp;#038;title=Future-proof%20monolithic%20applications%20with%20modular%20design" data-a2a-url="https://developers.redhat.com/blog/2019/12/12/future-proof-monolithic-applications-with-modular-design/" data-a2a-title="Future-proof monolithic applications with modular design"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/12/future-proof-monolithic-applications-with-modular-design/"&gt;Future-proof monolithic applications with modular design&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1gw8dh6L0co" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;DevNation tech talks are hosted by the Red Hat technologists who create our products. These sessions include real solutions and code and sample projects to help you get started. In this talk, you’ll learn about future-proofing applications from Eric Murphy and Ales Nosek, Architects with Red Hat Consulting. When building an MVP software application, you [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/12/future-proof-monolithic-applications-with-modular-design/"&gt;Future-proof monolithic applications with modular design&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">657987</post-id><dc:creator>Editorial Team</dc:creator><dc:date>2019-12-12T08:00:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/12/future-proof-monolithic-applications-with-modular-design/</feedburner:origLink></entry><entry><title>MicroProfile 3.2 is now available on Open Liberty in Red Hat Runtimes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/C7UNl7AIc1s/" /><category term="Java" /><category term="Microservices" /><category term="Open source" /><category term="Red Hat OpenShift Application Runtimes" /><category term="Open Liberty" /><author><name>Laura Cowen</name></author><id>https://developers.redhat.com/blog/?p=662727</id><updated>2019-12-11T13:56:41Z</updated><published>2019-12-11T13:56:41Z</published><content type="html">&lt;p&gt;&lt;a href="https://openliberty.io/about/"&gt;Open Liberty&lt;/a&gt; 19.0.0.12 provides support for &lt;a href="https://microprofile.io/"&gt;MicroProfile 3.2&lt;/a&gt;, allowing users to provide their own health check procedures and monitor microservice applications easily with metrics. Additionally, updates allow trust to be established using the JDK&amp;#8217;s default truststore or a certificate through an environment variable.&lt;/p&gt; &lt;p&gt;In Open Liberty 19.0.0.12:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#mp32"&gt;MicroProfile 3.2 support&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#hc21"&gt;Provide your own health check procedures (MicroProfile Health Check 2.1)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#hm22"&gt;Monitor microservice applications easily wth metrics (MicroProfile Metrics 2.2)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#jmo"&gt;Jaeger support in MicroProfile Open Tracing&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#ssl"&gt;Trusted certificate enhancements (Transport Security 1.0)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#rrs"&gt;Liberty reader role support&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Run your apps using 19.0.0.12&lt;/h2&gt; &lt;p&gt;If you&amp;#8217;re using &lt;a href="https://openliberty.io/guides/maven-intro.html"&gt;Maven&lt;/a&gt;, here are the coordinates:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;io.openliberty&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;openliberty-runtime&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;19.0.0.12&amp;#60;/version&amp;#62; &amp;#60;type&amp;#62;zip&amp;#60;/type&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;Or for &lt;a href="https://openliberty.io/guides/gradle-intro.html"&gt;Gradle&lt;/a&gt;:&lt;/p&gt; &lt;pre class="brush: plain; title: ; notranslate"&gt; dependencies { libertyRuntime group: 'io.openliberty', name: 'openliberty-runtime', version: '[19.0.0.12,)' } &lt;/pre&gt; &lt;p&gt;Or if you&amp;#8217;re using &lt;a href="https://openliberty.io/guides/containerize.html"&gt;Docker&lt;/a&gt;:&lt;/p&gt; &lt;pre class="brush: plain; title: ; notranslate"&gt; FROM open-liberty &lt;/pre&gt; &lt;div id="mp32"&gt; &lt;h2&gt;MicroProfile 3.2 support&lt;/h2&gt; &lt;p&gt;Add the whole of MicroProfile 3.2 to your application with this convenience feature in your &lt;code&gt;server.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;featureManager&amp;#62; &amp;#60;feature&amp;#62;microProfile-3.2&amp;#60;/feature&amp;#62; &amp;#60;featureManager&amp;#62; &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;microProfile-3.2&lt;/code&gt; feature automatically includes the following features in your app: JAX-RS 2.1, CDI 2.0, JSON-P 1.1, JSON-B 1.0, MicroProfile Config 1.3, MicroProfile Fault Tolerance 2.0, MicroProfile Health Check 2.1, MicroProfile JWT 1.1, MicroProfile Metrics 2.2, MicroProfile OpenAPI 1.1, MicroProfile OpenTracing 1.3, and MicroProfile Rest Client 1.3.&lt;/p&gt; &lt;p&gt;The MicroProfile Health Check and Metrics features contain updates.&lt;/p&gt; &lt;div id="hc21"&gt; &lt;h3&gt;Provide your own health check procedures (MicroProfile Health Check 2.1)&lt;/h3&gt; &lt;p&gt;MicroProfile Health Check 2.1 enables you to provide your own health check procedures to be invoked by Liberty, to verify the health of your microservice:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; HealthCheckResponse.up(&amp;#34;myCheck&amp;#34;); &lt;/pre&gt; &lt;p&gt;In previous versions, to define a simple successful/failed named health check response, the application level code is always expected to use several static methods together from the HealthCheckResponse API to retrieve a HealthCheckResponseBuilder used to construct a HealthCheck response.&lt;/p&gt; &lt;p&gt;In the &lt;code&gt;mpHealth-2.1&lt;/code&gt; feature for OpenLiberty, you can now use convenient and simpler methods from standard Java APIs, to construct UP/DOWN named health check responses, in your applications, such as &lt;code&gt;HealthCheckResponse.named(“myCheck”).up().build();&lt;/code&gt;&lt;/p&gt; &lt;p&gt;To make it work include the following line in the &lt;code&gt;server.xml&lt;/code&gt; file:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;feature&amp;#62;mpHealth-2.1&amp;#60;/feature&amp;#62; &lt;/pre&gt; &lt;p&gt;Applications are expected to provide health check procedures by implementing the HealthCheck interface with the &lt;code&gt;@Liveness&lt;/code&gt; or &lt;code&gt;@Readiness&lt;/code&gt; annotations, which are used by Liberty to verify the Liveness or Readiness of the application, respectively. Add the logic of your health check in the &lt;code&gt;call()&lt;/code&gt; method, and return the HealthCheckResponse object by constructing using the simple &lt;code&gt;up()&lt;/code&gt; and &lt;code&gt;down()&lt;/code&gt; methods from the API. To view the status of each health check, access either the &lt;code&gt;+http://:/health/live+&lt;/code&gt; or &lt;code&gt;+http://:/health/ready+&lt;/code&gt; endpoints.&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; **Liveness Check** @Liveness @ApplicationScoped public class AppLiveCheck implements HealthCheck { ... @Override public HealthCheckResponse call() { ... HealthCheckResponse.up(&amp;#34;myCheck&amp;#34;); ... } } &lt;/pre&gt; &lt;p&gt;For more information:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/eclipse/microprofile-health/releases/tag/2.1"&gt;MicroProfile Health Check 2.1 Release Page&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://download.eclipse.org/microprofile/microprofile-health-2.1/apidocs/"&gt;Javadocs&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://download.eclipse.org/microprofile/microprofile-health-2.1/microprofile-health-spec.html"&gt;Specification document&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div id="hm22"&gt; &lt;h3&gt;Monitor microservice applications easily wth metrics (MicroProfile Metrics 2.2 )&lt;/h3&gt; &lt;p&gt;MicroProfile Metrics 2.2 enables developers to instrument metrics in their (microservice) applications for easy monitoring by their operations team.&lt;/p&gt; &lt;p&gt;Previously, the MetadataBuilder API had &lt;code&gt;reusable()&lt;/code&gt; and &lt;code&gt;notReusable()&lt;/code&gt; method to set the reusable field to &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;. The MetadataBuilder API has been changed to include a new setter method for the reusable attribute. This change is implemented so the MetadataBuilder API follows the builder pattern.&lt;/p&gt; &lt;p&gt;To enable the feature in the &lt;code&gt;server.xml&lt;/code&gt; file:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;feature&amp;#62;mpMetrics-2.2&amp;#60;/feature&amp;#62; &lt;/pre&gt; &lt;p&gt;The example shows how to set the reusable field with the MetadataBuilder API:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; MetadataBuilder mdb = Metadata.builder(); &lt;/pre&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; mdb = mdb.withName(&amp;#34;metricName&amp;#34;).withType(MetricType.COUNTER) .reusable(resolveIsReusable()); &lt;/pre&gt; &lt;p&gt;For more information:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Changes to MicroProfile metrics&lt;/li&gt; &lt;li&gt;Microserice observability metrics&lt;/li&gt; &lt;/ul&gt; &lt;div id="jmo"&gt; &lt;h2&gt;Jaeger support added for tracing (MicroProfile OpenTracing 1.3)&lt;/h2&gt; &lt;p&gt;Open Liberty has added support for Jaeger in MicroProfile OpenTracing. A &lt;a href="https://github.com/WASdev/sample.opentracing.zipkintracer"&gt;sample tracer is available&lt;/a&gt; for using Zipkin as a tracing backend. With the addition of Jaeger support, developers can also use Jaeger as a tracing backend.&lt;/p&gt; &lt;p&gt;You can download the Jaeger client version 0.34.0 library and its dependencies from &lt;a href="https://mvnrepository.com/artifact/io.jaegertracing/jaeger-client/0.34.0"&gt;Maven repository&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In the server.xml:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;library id=&amp;#34;jaegerLib&amp;#34; apiTypeVisibility=&amp;#34;+third-party&amp;#34; &amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/gson-2.8.2.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/jaeger-client-0.34.0.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/jaeger-core-0.34.0.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/jaeger-thrift-0.34.0.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/jaeger-tracerresolver-0.34.0.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/libthrift-0.12.0.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/slf4j-api-1.7.25.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/slf4j-jdk14-1.7.25.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/opentracing-util-0.31.0.jar&amp;#34; /&amp;#62; &amp;#60;file name=&amp;#34;&amp;#60;path&amp;#62;/jaegerLib_0.34/opentracing-noop-0.31.0.jar&amp;#34; /&amp;#62; &amp;#60;/library&amp;#62; &lt;/pre&gt; &lt;p&gt;Define your application:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;webApplication location=&amp;#34;yourapp.war&amp;#34; contextRoot=&amp;#34;/yourapp&amp;#34;&amp;#62; &amp;#60;!-- enable visibility to third party apis --&amp;#62; &amp;#60;classloader commonLibraryRef=&amp;#34;jaegerLib&amp;#34; apiTypeVisibility=&amp;#34;+third-party&amp;#34; /&amp;#62; &amp;#60;/webApplication&amp;#62; &lt;/pre&gt; &lt;p&gt;You can find out more about Jaeger settings set up using environment variables by looking at &lt;a href="https://github.com/jaegertracing/jaeger-client-java/blob/10c641f8df6316f1eac4d5b1715513275bcd724e/jaeger-core/README.md"&gt;jaeger-client-java readme&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For the &lt;code&gt;JAEGER_PASSWORD&lt;/code&gt; environment variable, the password can be encoded using the securityUtility command. Depending on Jaeger&amp;#8217;s sampling settings &lt;code&gt;JAEGER_SAMPLER_TYPE&lt;/code&gt; and &lt;code&gt;JAEGER_SAMPLER_PARAM&lt;/code&gt;, Jaeger may not report every spans created by the applications.&lt;/p&gt; &lt;div id="ssl"&gt; &lt;h2&gt;Trusted certificate enhancements (Transport Security 1.0)&lt;/h2&gt; &lt;p&gt;Open Liberty now offers new options to help establish trust for TLS connections. An easy way to use the JDK&amp;#8217;s default truststore for trust and a way to pass the certificate needed to establish trust to a truststore through an environment variable is now provided.&lt;/p&gt; &lt;h3&gt;Establishing trust using the JDK&amp;#8217;s default truststore&lt;/h3&gt; &lt;p&gt;By default, the JDK default truststore is the &lt;code&gt;cacerts&lt;/code&gt; file. The default truststore may be set by the &lt;code&gt;javax.net.ssl.truststore&lt;/code&gt; system property or the &lt;code&gt;jssecacerts&lt;/code&gt; file if users have one configured. For Open Liberty to use what is configured as the JDK default truststore the &lt;code&gt;useDefaultCerts&lt;/code&gt; attribute needs to be set to &lt;code&gt;true&lt;/code&gt; on the &lt;code&gt;ssl&lt;/code&gt; element. It is set to &lt;code&gt;false&lt;/code&gt; by default. For example:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;ssl id=&amp;#34;defaultSSLConfig&amp;#34; keyStoreRef=&amp;#34;defaultKeyStore&amp;#34; trustStoreRef=&amp;#34;defaultTrustStore&amp;#34; trustDefaultCerts=&amp;#34;true&amp;#34; /&amp;#62; &amp;#60;keyStore id=&amp;#34;defaultKeyStore&amp;#34; location=&amp;#34;key.p12&amp;#34; type=&amp;#34;PKCS12&amp;#34; password=&amp;#60;your password&amp;#62; /&amp;#62; &amp;#60;keyStore id=&amp;#34;defaultTrustStore&amp;#34; location=&amp;#34;trust.p12&amp;#34; type=&amp;#34;PKCS12&amp;#34; password=&amp;#60;your password&amp;#62; /&amp;#62; &lt;/pre&gt; &lt;p&gt;With &lt;code&gt;trustDefaultCerts&lt;/code&gt; set to &lt;code&gt;true&lt;/code&gt;, the server will try to establish trust with the configured truststore, in this case &lt;code&gt;defaultTrustStore&lt;/code&gt;, first. If trust is not establish with the configured truststore then it will try to use the JDK&amp;#8217;s default truststore to establish trust.&lt;/p&gt; &lt;h3&gt;Providing a certificate through an environment variable to establish trust&lt;/h3&gt; &lt;p&gt;Open Liberty will read a certificate from an environment variable and add it to a keystore or truststore so it can be used for trust. The certificate will be added to the runtime copy of the keystore or truststore and will not be stored to the file system. If the keystore configuration includes the &lt;code&gt;readOnly&lt;/code&gt; attribute set to &lt;code&gt;true&lt;/code&gt; then the certificate will not be included.&lt;/p&gt; &lt;p&gt;The environment variable key must be in the format &lt;code&gt;cert_ + keystore id&lt;/code&gt;. For example:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;keyStore id=&amp;#34;myKeyStore&amp;#34; location=&amp;#34;myKey.p12&amp;#34; type=&amp;#34;PKCS12&amp;#34; password=&amp;#60;your password&amp;#62; /&amp;#62; &lt;/pre&gt; &lt;p&gt;The key of the environment variable should be &lt;code&gt;cert_myKeyStore&lt;/code&gt; (it is case-sensitive).&lt;/p&gt; &lt;p&gt;The value of the environment variable can either be a certificate in the base 64-bit format or the path to a file containing a base 64-bit encode certificate or DER-encoded certificate. If using the base 64-bit encode certificate directly on the environment variable, it must contain the &lt;code&gt;-----BEGIN CERTIFICATE-----&lt;/code&gt; and &lt;code&gt;-----END CERTIFICATE-----&lt;/code&gt; tags. For example:&lt;/p&gt; &lt;pre class="brush: plain; title: ; notranslate"&gt; cert_myKeyStore=&amp;#34;-----BEGIN CERTIFICATE----- .... -----END CERTIFICATE-----&amp;#34; &lt;/pre&gt; &lt;p&gt;The environment variable for a file will look similar to:&lt;/p&gt; &lt;p&gt;&lt;code&gt;cert_myKeyStore=/Users/me/servercert.crt&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Any value not starting with the &lt;code&gt;-----BEGIN CERTIFICATE-----&lt;/code&gt; tag will be treated like a file.&lt;/p&gt; &lt;p&gt;[#rrs]&lt;/p&gt; &lt;h2&gt;Liberty reader role support (Application Security 2.0 and Application Security 3.0)&lt;/h2&gt; &lt;p&gt;The reader role is a management role that allows read-only access to select administrative REST APIs as well as the Admin Center UI (&lt;code&gt;adminCenter-1.0&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;Prior to this release, the Administrator management role was the only management role within Open Liberty and it provided read and write access. The new Reader management role provides the ability to assign a read-only role to users and groups. This will allow those users and groups to monitor the server without granting those users the ability to modify the server in anyway.&lt;/p&gt; &lt;p&gt;Using the new Reader management role is nearly identical to using the Administrator management role. In the &lt;code&gt;server.xml&lt;/code&gt; include the &lt;code&gt;appSecurity-2.0&lt;/code&gt; or &lt;code&gt;appSecurity-3.0&lt;/code&gt; feature and also add the new &lt;code&gt;reader-role&lt;/code&gt; configuration element, that specifies the group(s), user(s), and/or the access ID of the group(s) or user(s) that should be granted the Reader management role.&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;server&amp;#62; &amp;#60;featureManager&amp;#62; &amp;#60;feature&amp;#62;appSecurity-3.0&amp;#60;/feature&amp;#62; &amp;#60;/featureManager&amp;#62; &amp;#60;reader-role&amp;#62; &amp;#60;group&amp;#62;group&amp;#60;/group&amp;#62; &amp;#60;group-access-id&amp;#62;group:realmName/groupUniqueId&amp;#60;/group-access-id&amp;#62; &amp;#60;user&amp;#62;user&amp;#60;/user&amp;#62; &amp;#60;user-access-id&amp;#62;user:realmName/userUniqueId&amp;#60;/user-access-id&amp;#62; &amp;#60;/reader-role&amp;#62; &amp;#60;/server&amp;#62; &lt;/pre&gt; &lt;h2&gt;Try Open Liberty 19.0.0.12 in Red Hat Runtimes now&lt;/h2&gt; &lt;p&gt;Open Liberty is part of the Red Hat Runtimes offering. If you&amp;#8217;re a &lt;a href="https://access.redhat.com/products/red-hat-runtimes"&gt;Red Hat Runtimes subscriber&lt;/a&gt;, you can try Open Liberty now.&lt;/p&gt; &lt;p&gt;To learn more about deploying Open Liberty applications to OpenShift, take a look at our &lt;a href="https://openliberty.io/guides/cloud-openshift.html"&gt;Open Liberty guide: Deploying microservices to OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#38;linkname=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#38;linkname=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#38;linkname=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#38;linkname=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#38;linkname=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#38;linkname=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#38;linkname=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fmicroprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes%2F&amp;#038;title=MicroProfile%203.2%20is%20now%20available%20on%20Open%20Liberty%20in%20Red%20Hat%20Runtimes" data-a2a-url="https://developers.redhat.com/blog/2019/12/11/microprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes/" data-a2a-title="MicroProfile 3.2 is now available on Open Liberty in Red Hat Runtimes"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/11/microprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes/"&gt;MicroProfile 3.2 is now available on Open Liberty in Red Hat Runtimes&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/C7UNl7AIc1s" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Open Liberty 19.0.0.12 provides support for MicroProfile 3.2, allowing users to provide their own health check procedures and monitor microservice applications easily with metrics. Additionally, updates allow trust to be established using the JDK&amp;#8217;s default truststore or a certificate through an environment variable. In Open Liberty 19.0.0.12: MicroProfile 3.2 support Provide your own health check [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/11/microprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes/"&gt;MicroProfile 3.2 is now available on Open Liberty in Red Hat Runtimes&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">662727</post-id><dc:creator>Laura Cowen</dc:creator><dc:date>2019-12-11T13:56:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/11/microprofile-3-2-is-now-available-on-open-liberty-in-red-hat-runtimes/</feedburner:origLink></entry><entry><title>Keycloak: Core concepts of open source identity and access management</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/0MFvLHTm98k/" /><category term="Red Hat SSO" /><category term="Security" /><category term="keycloak" /><author><name>akoserwa</name></author><id>https://developers.redhat.com/blog/?p=654787</id><updated>2019-12-11T08:00:38Z</updated><published>2019-12-11T08:00:38Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2018/03/19/sso-made-easy-keycloak-rhsso/"&gt;Keycloak&lt;/a&gt; provides the flexibility to export and import configurations easily, using a single view to manage everything. Together, these technologies let you integrate front-end, mobile, and monolithic applications into a &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservice&lt;/a&gt; architecture. In this article, we discuss the core concepts and features of &lt;a href="https://www.keycloak.org" target="_blank" rel="noopener noreferrer"&gt;Keycloak&lt;/a&gt; and its application integration mechanisms. You will find links to implementation details near the end.&lt;/p&gt; &lt;h2&gt;Core concepts&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s start with Keycloak&amp;#8217;s core concepts, as shown in Figure 1:&lt;/p&gt; &lt;div id="attachment_657657" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657657" class="wp-image-657657 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak1-1024x587.png" alt="Keycloak core concepts" width="640" height="367" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak1-1024x587.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak1-300x172.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak1-768x440.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak1.png 1565w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657657" class="wp-caption-text"&gt;Figure 1: Keycloak&amp;#8217;s core concepts.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;A Keycloak &lt;em&gt;realm&lt;/em&gt; is like a namespace that allows you to manage all of your metadata and configurations. You can have multiple realms based on your requirements. Generally, it is recommended to avoid using the &lt;em&gt;master realm&lt;/em&gt;, which is for administration purposes only.&lt;/p&gt; &lt;p&gt;In Figure 1, you can see the information that Keycloak lets you manage, namely:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Clients (per application)&lt;/li&gt; &lt;li&gt;Configuration management&lt;/li&gt; &lt;li&gt;Custom themes (UI)&lt;/li&gt; &lt;li&gt;Events&lt;/li&gt; &lt;li&gt;Federation&lt;/li&gt; &lt;li&gt;LDAP or Active Directory integration&lt;/li&gt; &lt;li&gt;User management (users and groups)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can have one client that contains configuration information for a single application, such as the URL, protocol, and redirect URI.&lt;/p&gt; &lt;p&gt;Figure 2 shows how Keycloak gives you access to all of this information in a single view:&lt;/p&gt; &lt;div id="attachment_657707" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657707" class="size-large wp-image-657707" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak2-1024x562.png" alt="Keycloak's UI offers access to many settings." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak2-1024x562.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak2-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak2-768x421.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657707" class="wp-caption-text"&gt;Figure 2: Keycloak&amp;#8217;s UI offers access to many settings.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Why should you use Keycloak?&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s take a look at why you might choose Keycloak, aside from the sheer amount of management you can accomplish within a single view.&lt;/p&gt; &lt;h3&gt;Keycloak is reliable&lt;/h3&gt; &lt;p&gt;Keycloak is a reliable solution, designed following standard security protocols to provide a dynamic single sign-on solution. Red Hat runs on Red Hat products, which includes single sign-on (SSO), and Red Hat trusts the upstream product Keycloak for their downstream product &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on" target="_blank" rel="noopener noreferrer"&gt;Red Hat SSO&lt;/a&gt;. Red Hat SSO handles Red Hat&amp;#8217;s entire authentication and authorization system. Additionally, Keycloak is licensed under &lt;a href="https://github.com/keycloak/keycloak/blob/master/License.html" target="_blank" rel="noopener nofollow noreferrer"&gt;Apache License Version 2.0&lt;/a&gt; and has a strong and active open source community.&lt;/p&gt; &lt;h3&gt;Keycloak supports standard protocols&lt;/h3&gt; &lt;p&gt;Keycloak supports the following standard protocols:&lt;/p&gt; &lt;ul class=""&gt; &lt;li&gt;OAuth 2.0&lt;/li&gt; &lt;li&gt;OpenID Connect&lt;/li&gt; &lt;li&gt;SAML 2.0&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This support means that any tool or application that supports integration with the above protocols can be plugged into with Keycloak (for example, enterprise applications like &lt;a href="https://access.redhat.com/products/ansible-tower-red-hat" target="_blank" rel="noopener noreferrer"&gt;Red Hat Ansible Tower&lt;/a&gt; or SAP Business Intelligence Platform).&lt;/p&gt; &lt;h3&gt;Keycloak is ready for production&lt;/h3&gt; &lt;p&gt;As mentioned earlier, Keycloak is already being used in production. Before doing so yourself, make sure to go through the production-readiness documentation.&lt;/p&gt; &lt;h2&gt;Launching Keycloak&lt;/h2&gt; &lt;p&gt;To launch Keycloak with Docker, use:&lt;/p&gt; &lt;pre&gt;$ docker pull jboss/keycloak $ docker run -d -e KEYCLOAK_USER=&amp;#60;USERNAME&amp;#62; -e KEYCLOAK_PASSWORD=&amp;#60;PASSWORD&amp;#62; -p 8081:8080 jboss/keycloak&lt;/pre&gt; &lt;p&gt;However, your configuration information (like realm settings, clients, or certificates) will be temporary in this scenario. Therefore, export the configuration and re-import every time before you instantiate a new container. In other words, use a persistent volume for storing the state.&lt;/p&gt; &lt;p&gt;To do a standalone Keycloak launch (&lt;a href="https://www.keycloak.org/downloads.html" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.keycloak.org/downloads.html&lt;/a&gt;) with JBoss WildFly, use:&lt;/p&gt; &lt;pre&gt;$ keycloak-x.x.x.Final/bin&amp;#62;./standalone.sh&lt;/pre&gt; &lt;h2&gt;Preparing to integrate with Keycloak&lt;/h2&gt; &lt;p&gt;Once you&amp;#8217;re ready to integrate your apps, tools, and services with Keycloak, you have decisions to make (see Figure 3):&lt;/p&gt; &lt;div id="attachment_657747" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657747" class="wp-image-657747 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak3-1024x576.png" alt="Keycloak integration relationship map." width="640" height="360" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak3-1024x576.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak3-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/keycloak3-768x432.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657747" class="wp-caption-text"&gt;Figure 3: Keycloak integration map.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;First, you need to decide which protocol you intend to use, such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;OAuth2&lt;/li&gt; &lt;li&gt;OpenID Connect&lt;/li&gt; &lt;li&gt;Security Assertion Markup Language (SAML).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Are you looking for &lt;em&gt;authentication&lt;/em&gt; or &lt;em&gt;authorization&lt;/em&gt;?&lt;/p&gt; &lt;pre&gt;OAuth 2&lt;em&gt; != Authentication&lt;/em&gt;, only &lt;strong&gt;Authorization &lt;/strong&gt; OpenID Connect = Identity + Authentication + Authorization&lt;/pre&gt; &lt;p&gt;Now, regarding the application:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Is it running on a container (stateless) or is it in a legacy clustered (shared state) environment?&lt;/li&gt; &lt;li&gt;What does the architecture consist of, such as single-page applications (SPA), microservices, serverless, or MVC?&lt;/li&gt; &lt;li&gt;Identify the resources and endpoints you want to secure. Is your integration between, for example, client and server, service-to-service, or API endpoints.&lt;/li&gt; &lt;li&gt;Identify which adapter will be suited for your architecture.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Integrating with Keycloak&lt;/h2&gt; &lt;p&gt;To integrate your apps with Keycloak:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a realm. You can use &lt;code&gt;master&lt;/code&gt; for a dev environment or base it on your business domain (for example, &lt;code&gt;external-apps&lt;/code&gt;or &lt;code&gt;internal-apps&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;Create a client for your application (for example, &lt;code&gt;hello-world-app&lt;/code&gt;). Client configuration requires details like this: &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Protocol:&lt;/strong&gt; Which protocol, such as SAML or OpenID.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Resource Endpoint:&lt;/strong&gt; The application hostname or REST endpoint.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Redirect URI:&lt;/strong&gt; Where to redirect the user when authentication is granted.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Provide the client configuration to your application as input, such as: &lt;ul class=""&gt; &lt;li&gt;The clientId (i.e.,&lt;code&gt;hello-world-app&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;The realm (i.e.,&lt;code&gt;external-apps&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;The Keycloak server&amp;#8217;s URL.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;That’s all you need to do in order to configure your application with Keycloak.&lt;/p&gt; &lt;h2&gt;Wrapping up&lt;/h2&gt; &lt;p&gt;In conclusion, you can refer to the following integration patterns when you work with Keycloak yourself:&lt;/p&gt; &lt;ul class=""&gt; &lt;li&gt;&lt;a href="https://medium.com/keycloak/secure-vue-js-app-with-keycloak-94814181e344" target="_blank" rel="noopener noreferrer"&gt;Vue&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/keycloak/secure-angular-app-with-keycloak-63ec934e5093" target="_blank" rel="noopener noreferrer"&gt;Angular&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/keycloak/secure-react-app-with-keycloak-4a65614f7be2" target="_blank" rel="noopener noreferrer"&gt;React&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/keycloak/secure-spring-boot-2-using-keycloak-f755bc255b68" target="_blank" rel="noopener noreferrer"&gt;Spring-boot 2&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a class="bo dc jz ka kb kc" href="https://medium.com/keycloak/quarkus-and-react-integration-with-keycloak-e03eb82d8cd" target="_blank" rel="noopener noreferrer"&gt;Quarkus and React&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;References&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.keycloak.org/documentation.html" target="_blank" rel="noopener noreferrer"&gt;Keycloak Documentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.keycloak.org/docs/latest/securing_apps/index.html"&gt;Securing Applications and Services Guide&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Happy secure coding!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#38;linkname=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#38;linkname=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#38;linkname=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#38;linkname=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#38;linkname=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#38;linkname=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#38;linkname=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F11%2Fkeycloak-core-concepts-of-open-source-identity-and-access-management%2F&amp;#038;title=Keycloak%3A%20Core%20concepts%20of%20open%20source%20identity%20and%20access%20management" data-a2a-url="https://developers.redhat.com/blog/2019/12/11/keycloak-core-concepts-of-open-source-identity-and-access-management/" data-a2a-title="Keycloak: Core concepts of open source identity and access management"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/11/keycloak-core-concepts-of-open-source-identity-and-access-management/"&gt;Keycloak: Core concepts of open source identity and access management&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/0MFvLHTm98k" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Keycloak provides the flexibility to export and import configurations easily, using a single view to manage everything. Together, these technologies let you integrate front-end, mobile, and monolithic applications into a microservice architecture. In this article, we discuss the core concepts and features of Keycloak and its application integration mechanisms. You will find links to implementation details [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/11/keycloak-core-concepts-of-open-source-identity-and-access-management/"&gt;Keycloak: Core concepts of open source identity and access management&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">654787</post-id><dc:creator>akoserwa</dc:creator><dc:date>2019-12-11T08:00:38Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/11/keycloak-core-concepts-of-open-source-identity-and-access-management/</feedburner:origLink></entry><entry><title>This Week in JBoss, 10th December 2019 - Camel 3, Infinispan 10.1, Keycloak 8... A bucketload of releases!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/a5ToOBWtoac/this-week-in-jboss-10th-december-2019-camel-3-infinispan-101-keycloak-8-a-bucketload-of-releases" /><category term="AMQ" scheme="searchisko:content:tags" /><category term="Camel" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="infinispan-10" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="kogito" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="narayana" scheme="searchisko:content:tags" /><category term="Operators" scheme="searchisko:content:tags" /><author><name>Romain Pelisse</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_10th_december_2019_camel_3_infinispan_10_1_keycloak_8_a_bucketload_of_releases</id><updated>2019-12-10T14:49:26Z</updated><published>2019-12-10T14:49:26Z</published><content type="html">&lt;!-- [DocumentBodyStart:5ee2f36e-7030-4c29-b663-04f6ff4b06a9] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;&lt;em&gt;There've been some noteworthy releases in the last two weeks such as &lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/12/09/infinispan-10/" rel="nofollow"&gt;Infinispan 10.1.0.CR1&lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://www.keycloak.org/2019/12/keycloak-801-released.html" rel="nofollow"&gt;Keycloak 8.0.1&lt;/a&gt; and, of course, &lt;a class="jive-link-external-small" href="http://janstey.blogspot.com/2019/11/apache-camel-3-is-out.html" rel="nofollow"&gt;Camel 3.0&lt;/a&gt; !&amp;#160; Just taking a look at all the new cool features coming with those should already keep you busy! But if it&amp;#8217;s not enough, don&amp;#8217;t worry, the rest of the JBoss community has you covered!&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://farm1.staticflickr.com/755/22604188601_612696b9a7_b.jpg"&gt;&lt;img alt="" class="image-1 jive-image" src="https://farm1.staticflickr.com/755/22604188601_612696b9a7_b.jpg" style="width: 620px; height: 453px; display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;Pimp your tooling&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Developers like sysadmins can only accomplish their work properly with the right tooling. What could a developer do nowadays without Github or a decent IDE? Same goes for admin. That&amp;#8217;s why you might be interested to know about a couple of new tools that have been released in the last weeks. The first one is a &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/25/kogito-tooling-for-friendly-dmn-and-bpmn-visualization-on-github/" rel="nofollow"&gt;Kogito tooling for friendly DMN and BPMN visualization on GitHub &lt;/a&gt;&amp;mdash; if you do anything with BPMN and/or Kogito, you should definitely check it out! We&amp;#8217;ve mentioned IDE as being a crucial tool for the developer, so you&amp;#8217;ll be happy to read about the &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/21/new-features-in-quarkus-tools-for-visual-studio-code-1-2-0/" rel="nofollow"&gt;New features in Quarkus Tools for Visual Studio Code 1.2.0&lt;/a&gt;!&lt;/p&gt;&lt;p&gt;Beyond tooling, knowledge is also a strong ally of the developer, so maybe checking this &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/02/new-eclipse-microprofile-book-provides-introduction-to-enterprise-java-microservices/" rel="nofollow"&gt;New Eclipse MicroProfile book provides introduction to enterprise Java microservices&lt;/a&gt; might do you good &lt;span aria-label="Happy" class="emoticon_happy emoticon-inline" style="height:16px;width:16px;"&gt;&lt;/span&gt;. As we are talking theorical matter and concept, you should also take a look at this article on&lt;/p&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/03/testing-in-production-from-devtestoops-to-devtestops/" rel="nofollow"&gt;Testing in production: From DevTestOops to DevTestOps&lt;/a&gt;...&lt;/p&gt;&lt;p&gt;&lt;a href="https://live.staticflickr.com/6193/6074298666_2017626332_b.jpg"&gt;&lt;img alt="" class="image-2 jive-image" src="https://live.staticflickr.com/6193/6074298666_2017626332_b.jpg" style="width: 620px; height: 465px; display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;All you ever wanted to know about AMQ Streams (even on OpenShift!)&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;OK, if you ever wanted to learn anything or everything on the AMQ Streams you are in for a treat. First, you have a nice overview of &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/21/event-based-microservices-with-red-hat-amq-streams/" rel="nofollow"&gt;Event-based microservices with Red Hat AMQ Streams&lt;/a&gt;&lt;/p&gt;&lt;p&gt;, but if it&amp;#8217;s not enough you have a three parts detailed series on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/04/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-1/" rel="nofollow"&gt;Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes (Part 1) &lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/05/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2/" rel="nofollow"&gt;Part 2&lt;/a&gt; and &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/06/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3/" rel="nofollow"&gt;Part 3&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;a href="https://farm5.staticflickr.com/4641/38237140825_f078a14863_b.jpg"&gt;&lt;img alt="" class="image-3 jive-image" src="https://farm5.staticflickr.com/4641/38237140825_f078a14863_b.jpg" style="width: 620px; height: 414px; display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Releases, releases, releases...&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="http://janstey.blogspot.com/2019/11/apache-camel-3-is-out.html" rel="nofollow"&gt;Jon Anstey's Blog: Apache Camel 3 is out!! &lt;/a&gt;&lt;/li&gt;&lt;li&gt;Check out &lt;a class="jive-link-external-small" href="http://www.davsclaus.com/2019/12/apache-camel-3-whats-new-top-10.html" rel="nofollow"&gt;this article&lt;/a&gt; to know more about the main new features&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/12/09/infinispan-10/" rel="nofollow"&gt;Infinispan 10.1.0.CR1 - Infinispan&lt;/a&gt; along with&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/11/25/infinispan-operator-1/" rel="nofollow"&gt;Infinispan Operator 1.0.1 - Infinispan&lt;/a&gt; and&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/12/02/image/" rel="nofollow"&gt;Infinispan's new image - Infinispan&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="http://jbossts.blogspot.com/2019/12/narayana-5101final-released.html" rel="nofollow"&gt;Narayana team blog: Narayana 5.10.1.Final released&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://www.keycloak.org/2019/12/keycloak-801-released.html" rel="nofollow"&gt;Keycloak - Blog - Keycloak 8.0.1 released&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;em&gt;That's all for another edition of the JBoss Editorial, please join us again for more exciting development from the JBoss Communities.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:5ee2f36e-7030-4c29-b663-04f6ff4b06a9] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/a5ToOBWtoac" height="1" width="1" alt=""/&gt;</content><summary>There've been some noteworthy releases in the last two weeks such as Infinispan 10.1.0.CR1, Keycloak 8.0.1 and, of course, Camel 3.0 !  Just taking a look at all the new cool features coming with those should already keep you busy! But if it’s not enough, don’t worry, the rest of the JBoss community has you covered! Pimp your tooling   Developers like sysadmins can only accomplish their work prope...</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2019-12-10T14:49:26Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2019/12/10/this-week-in-jboss-10th-december-2019-camel-3-infinispan-101-keycloak-8-a-bucketload-of-releases</feedburner:origLink></entry><entry><title>LoRaWAN setup at the EclipseCon IoT playground</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-e9rSu8APmA/" /><category term="Integration" /><category term="Internet of Things" /><category term="Red Hat AMQ" /><category term="IoT solutions" /><category term="LoRaWAN" /><author><name>Jens Reimann</name></author><id>https://developers.redhat.com/blog/?p=653217</id><updated>2019-12-10T08:00:41Z</updated><published>2019-12-10T08:00:41Z</published><content type="html">&lt;p&gt;At the recent &lt;a href="https://www.eclipsecon.org/europe2019" target="_blank" rel="noopener noreferrer"&gt;EclipseCon Europe&lt;/a&gt; in Ludwigsburg, Germany, we had a big dashboard in the IoT playground area showing graphs of the number of WiFi devices, the temperature, and air quality, all transmitted via &lt;a href="https://lora-alliance.org/about-lorawan" target="_blank" rel="noopener noreferrer"&gt;LoRaWAN&lt;/a&gt;. We worked on this project during the community day and kept the setup throughout the conference, where we showed it and played with it even further. This article describes the architecture of the setup and gives pointers to replicate it.&lt;/p&gt; &lt;p&gt;&lt;span id="more-653217"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;The sensors&lt;/h2&gt; &lt;p&gt;We chose this &lt;a href="https://github.com/cyberman54/ESP32-Paxcounter" target="_blank" rel="noopener noreferrer"&gt;PAX Counter&lt;/a&gt; as our sensor device. Based on the ESP32 and LoRaWAN, it allows you to measure the number of unique WiFi clients in the area. The PAX counter, as the name suggests, only counts devices. It doesn&amp;#8217;t track them, and this functionality is exactly what we wanted. Also, you can add extra sensors, and the BME680 air quality sensor is supported right out of the box. While it is great to have open source firmware, having a ready-to-run experience is great as well. Fortunately, this PAX counter gave us both.&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-653367 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-1024x602.jpg" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-1024x602.jpg" alt="Photo of LoRaWAN PAX Counter" width="640" height="376" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-1024x602.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-300x176.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-768x452.jpg 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;h2&gt;The cloud side&lt;/h2&gt; &lt;p&gt;To have good LoRa coverage, we deployed two &lt;a href="https://www.thethingsnetwork.org/docs/gateways/thethingsindoor/"&gt;Things Network Indoor&lt;/a&gt; gateways. Those devices are rather cheap and easy to set up, and two of them were fine to cover the whole venue. Our initial goal was to provide the data visualization in a simple Grafana dashboard so that people could get a feeling of what we deployed.&lt;/p&gt; &lt;p&gt;Our back-end architecture made use of Eclipse Hono, the Qpid Dispatch Router, and Apache Kafka, and looked like this:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-653237 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-1024x809.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-1024x809.png" alt="Architectural Diagram of the IoT Playground" width="640" height="506" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-1024x809.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-300x237.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-768x607.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;Forwarding telemetry data from The Things Network to a Grafana dashboard shouldn&amp;#8217;t require that many components. However, we had a little more in mind than just showing the data on a dashboard.&lt;/p&gt; &lt;h2&gt;Ready for more than LoRaWAN&lt;/h2&gt; &lt;p&gt;We teamed up with people from &lt;a href="https://developers.redhat.com/videos/youtube/GKYROutwJHU/"&gt;Eclipse MicroProfile&lt;/a&gt;, offering a connection to the data stream as well. For that, &lt;a href="https://developers.redhat.com/videos/youtube/CZhOJ_ysIiI/"&gt;Apache Kafka&lt;/a&gt; seemed to be the right choice. Kafka can persist the data stream and allow you to connect to it at a later time, restarting to consume from the beginning while the already existing dashboard would continue to receive data without any change or interruption. We also could add as many users as we liked, consuming the data like all the others.&lt;/p&gt; &lt;p&gt;We didn&amp;#8217;t want to limit ourselves to this single sensor, and only to LoRaWAN or The Things Network. This is where Eclipse Hono comes into play. It has the ability to normalize different IoT protocols, like the LoRaWAN uplink, or MQTT and Sigfox into AMQP 1.0. Using this tool gave us the ability to plug in any other data provider without the rest of the data pipeline noticing.&lt;/p&gt; &lt;h2&gt;Completing the setup&lt;/h2&gt; &lt;p&gt;Of course, there is the issue of data formats. Both Eclipse Hono and Kafka are payload agnostic. Unfortunately, the sensors have their own data format, and InfluxDB has its custom API. Bringing both together isn&amp;#8217;t too difficult, but it&amp;#8217;s simpler when using Apache Camel. A few lines of XML or Java, and you have two running bridges, one forwarding raw IoT data from the EnMasse messaging address to the Kafka topic. The other one, for parsing the payload, and injects it into the InfluxDB.&lt;/p&gt; &lt;p&gt;Why did we decide to parse the payload in the second step? Kafka makes it so easy to store each and every message coming from the IoT layer. The sensors provided more data than we wanted to insert into the time series database. By handling things this way, we still had the raw values available in the Kafka cluster, ready for everyone else to consume them if necessary.&lt;/p&gt; &lt;p&gt;After deploying all of the sensors, it was awesome to see this visualization come to life:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-653307 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-1024x456.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-1024x456.png" alt="Devices overview dashboard" width="640" height="285" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-1024x456.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-300x134.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-768x342.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;The big dashboard showed each sensor’s information with the number of WiFi devices, the current temperature, and an air quality index. By default, you could see the last three hours.&lt;/p&gt; &lt;h2&gt;Playing with Microprofile&lt;/h2&gt; &lt;p&gt;Of course, it would be great to do something more interesting with the data than just having a nice dashboard. That is what we started to play with during the community day by connecting a &lt;a href="https://quarkus.io/" target="_blank" rel="noopener noreferrer"&gt;Quarkus&lt;/a&gt; application to the Kafka data stream and beginning to process it. Unfortunately, setting up proper TLS and authentication took longer than anticipated, so we ran out of time.&lt;/p&gt; &lt;p&gt;However, that doesn’t stop us from continuing. The repository in the next section will definitely see Quarkus examples related to IoT.&lt;/p&gt; &lt;h2&gt;Try it for yourself&lt;/h2&gt; &lt;p&gt;Deploying this solution was actually rather easy, and it should be easy enough for you to replicate. After all, we reused existing components like EnMasse and Strimzi to deploy Hono and Kafka. Of course, you can do the same with &lt;a href="https://developers.redhat.com/blog/2019/05/14/bringing-iot-to-red-hat-amq-online/"&gt;Red Hat AMQ Online&lt;/a&gt; and &lt;a href="https://access.redhat.com/products/red-hat-amq" target="_blank" rel="noopener noreferrer"&gt;Red Hat AMQ Streams&lt;/a&gt;, as the LoRaWAN adapter is part of Red Hat AMQ Online 1.3&amp;#8217;s IoT tech preview.&lt;/p&gt; &lt;p&gt;You can find the deployment scripts in the GitHub repository &lt;a href="https://github.com/ctron/ece2019-iot-playground/" target="_blank" rel="noopener noreferrer"&gt;ctron/ece2019-iot-playground&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#038;title=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" data-a2a-url="https://developers.redhat.com/blog/2019/12/10/lorawan-setup-at-the-eclipsecon-iot-playground/" data-a2a-title="LoRaWAN setup at the EclipseCon IoT playground"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/10/lorawan-setup-at-the-eclipsecon-iot-playground/"&gt;LoRaWAN setup at the EclipseCon IoT playground&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-e9rSu8APmA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;At the recent EclipseCon Europe in Ludwigsburg, Germany, we had a big dashboard in the IoT playground area showing graphs of the number of WiFi devices, the temperature, and air quality, all transmitted via LoRaWAN. We worked on this project during the community day and kept the setup throughout the conference, where we showed it [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/10/lorawan-setup-at-the-eclipsecon-iot-playground/"&gt;LoRaWAN setup at the EclipseCon IoT playground&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">653217</post-id><dc:creator>Jens Reimann</dc:creator><dc:date>2019-12-10T08:00:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/10/lorawan-setup-at-the-eclipsecon-iot-playground/</feedburner:origLink></entry><entry><title>Infinispan 10.1.0.CR1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-pmfPi_HXVs/" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><category term="release candidate" scheme="searchisko:content:tags" /><author><name>Tristan Tarrant</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_10_1_0_cr1</id><updated>2019-12-09T12:55:22Z</updated><published>2019-12-09T12:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Dear Infinispan community,&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;as we are closing in on 10.1, we have been working on a lot of polishing and bugfixing.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_server"&gt;&lt;a class="anchor" href="#_server"&gt;&lt;/a&gt;Server&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The new console has received a lot of improvements,&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A new welcome page&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A command-line switch to specify an alternate logging configuration file&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_query"&gt;&lt;a class="anchor" href="#_query"&gt;&lt;/a&gt;Query&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The query components have been reorganized so that they are more modular.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_monitoring"&gt;&lt;a class="anchor" href="#_monitoring"&gt;&lt;/a&gt;Monitoring&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The introduction of histogram and timer metrics.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_stores"&gt;&lt;a class="anchor" href="#_stores"&gt;&lt;/a&gt;Stores&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The REST cache store has been updated to use the v2 RESTful API.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_removals_and_deprecations"&gt;&lt;a class="anchor" href="#_removals_and_deprecations"&gt;&lt;/a&gt;Removals and deprecations&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The old RESTful API (v1) has been removed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Infinispan Lucene Directory has been deprecated.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The memcached protocol server has been deprecated. If you were relying on this, come and talk to us about working on a binary protocol implementation.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_bug_fixes_clean_ups_and_documentation"&gt;&lt;a class="anchor" href="#_bug_fixes_clean_ups_and_documentation"&gt;&lt;/a&gt;Bug fixes, clean-ups and documentation&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Over 40 issues fixed including a lot of documentation updates. See the &lt;a href=""&gt;full list of changes and fixes&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_get_it_use_it_ask_us"&gt;&lt;a class="anchor" href="#_get_it_use_it_ask_us"&gt;&lt;/a&gt;Get it, Use it, Ask us!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Please &lt;a href="http://infinispan.org/download/"&gt;download&lt;/a&gt;, &lt;a href="https://issues.jboss.org/projects/ISPN"&gt;report bugs&lt;/a&gt;, &lt;a href="https://infinispan.zulipchat.com/"&gt;chat with us&lt;/a&gt;, ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/?tagnames=infinispan&amp;amp;sort=newest"&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Infinispan 10.1.0.Final is scheduled for December the 20th.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-pmfPi_HXVs" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispan community, as we are closing in on 10.1, we have been working on a lot of polishing and bugfixing. Server The new console has received a lot of improvements, A new welcome page A command-line switch to specify an alternate logging configuration file Query The query components have been reorganized so that they are more modular. Monitoring The introduction of histogram and timer met...</summary><dc:creator>Tristan Tarrant</dc:creator><dc:date>2019-12-09T12:00:00Z</dc:date><feedburner:origLink>http://infinispan.org/blog/2019/12/09/infinispan-10/</feedburner:origLink></entry></feed>
